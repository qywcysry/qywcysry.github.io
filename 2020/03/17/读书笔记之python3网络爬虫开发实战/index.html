<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="python3网络爬虫开发实战,">





  <link rel="alternate" href="/atom.xml" title="Hy0uka" type="application/atom+xml">






<meta name="description" content="[TOC] 第一章：环境配置Python3的安装推荐了Anaconda，注意环境变量配置。 作者推荐解决版本冲突问题的方法：将安装目录中的python.exe复制一份，命名为python3.exe，能够更好地区分python版本。 请求库的安装爬虫可以简单分为几步：抓取页面，分析页面和存储数据。在抓取页面的过程中，我们需要模拟浏览器向服务器发出请求，所以需要python库来实现HTTP请求操作。">
<meta name="keywords" content="python3网络爬虫开发实战">
<meta property="og:type" content="article">
<meta property="og:title" content="环境配置与爬虫基础">
<meta property="og:url" content="http://qywcysry.github.io/2020/03/17/读书笔记之python3网络爬虫开发实战/index.html">
<meta property="og:site_name" content="Hy0uka">
<meta property="og:description" content="[TOC] 第一章：环境配置Python3的安装推荐了Anaconda，注意环境变量配置。 作者推荐解决版本冲突问题的方法：将安装目录中的python.exe复制一份，命名为python3.exe，能够更好地区分python版本。 请求库的安装爬虫可以简单分为几步：抓取页面，分析页面和存储数据。在抓取页面的过程中，我们需要模拟浏览器向服务器发出请求，所以需要python库来实现HTTP请求操作。">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2020-04-01T14:56:46.911Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="环境配置与爬虫基础">
<meta name="twitter:description" content="[TOC] 第一章：环境配置Python3的安装推荐了Anaconda，注意环境变量配置。 作者推荐解决版本冲突问题的方法：将安装目录中的python.exe复制一份，命名为python3.exe，能够更好地区分python版本。 请求库的安装爬虫可以简单分为几步：抓取页面，分析页面和存储数据。在抓取页面的过程中，我们需要模拟浏览器向服务器发出请求，所以需要python库来实现HTTP请求操作。">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://qywcysry.github.io/2020/03/17/读书笔记之python3网络爬虫开发实战/">





  <title>环境配置与爬虫基础 | Hy0uka</title>
  








  <script src="https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css">

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

<script src="/live2d-widget/autoload.js"></script>
  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hy0uka</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Cyber Security</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://qywcysry.github.io/2020/03/17/读书笔记之python3网络爬虫开发实战/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hy0uka">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hy0uka">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">环境配置与爬虫基础</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-03-17T11:44:46+08:00">
                2020-03-17
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2020-04-01T22:56:46+08:00">
                2020-04-01
              </time>
            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/03/17/读书笔记之python3网络爬虫开发实战/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/03/17/读书笔记之python3网络爬虫开发实战/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <span class="post-meta-divider">|</span>
            <span id="busuanzi_value_page_pv"></span>次阅读
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>[TOC]</p>
<h3 id="第一章：环境配置"><a href="#第一章：环境配置" class="headerlink" title="第一章：环境配置"></a>第一章：环境配置</h3><h5 id="Python3的安装"><a href="#Python3的安装" class="headerlink" title="Python3的安装"></a>Python3的安装</h5><p>推荐了Anaconda，注意环境变量配置。</p>
<p>作者推荐解决版本冲突问题的方法：将安装目录中的python.exe复制一份，命名为python3.exe，能够更好地区分python版本。</p>
<h4 id="请求库的安装"><a href="#请求库的安装" class="headerlink" title="请求库的安装"></a>请求库的安装</h4><p>爬虫可以简单分为几步：抓取页面，分析页面和存储数据。在抓取页面的过程中，我们需要模拟浏览器向服务器发出请求，所以需要python库来实现HTTP请求操作。</p>
<ol>
<li>requests的安装</li>
</ol>
<p>分为pip+库名安装，wheel（原来后缀为.whl是这个意思，安装好wheel库后直接用pip3命令+文件名）安装与源码安装（这个没听过，cd requests，python3 setup.py install）。</p>
<p>2.Selenium的安装</p>
<p>Selenium是一个自动化测试工具，利用它可以驱使浏览器执行特定动作，如点击/下拉。对于JS渲染的页面非常有效。</p>
<p>安装方式同上，但还需要配置浏览器来配合其工作。</p>
<h5 id="ChromeDriver安装"><a href="#ChromeDriver安装" class="headerlink" title="ChromeDriver安装"></a>ChromeDriver安装</h5><p>安装ChromeDriver能够驱动Chrome完成相应的操作。注意在Chrome中输入chrome://version/查看版本，不同版本的Chrome与ChromeDriver不适配。</p>
<p>下载完后将ChromeDriver.exe放到Chrome安装的文件夹并配置环境变量（用户变量）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">命令行配置环境变量的快捷方式：</span><br><span class="line">export PATH=&quot;$PATH:复制的路径&quot;</span><br><span class="line">保存后执行如下命令：</span><br><span class="line">source ~/.profile</span><br><span class="line">测试：</span><br><span class="line">from selenium import webdriver</span><br><span class="line">browser = webdriver.Chrome()</span><br></pre></td></tr></table></figure>

<p>此处在cmd中执行该命令报错没有selenium这个模块，百度得知是selenium不能通过pip install安装，要到官网下载然后在解压路径下执行python setup.py install.就是第三种源码安装。这回总算没报错，算是每种方法都尝试过了。</p>
<h5 id="aiohttp的安装"><a href="#aiohttp的安装" class="headerlink" title="aiohttp的安装"></a>aiohttp的安装</h5><p>requests库是一个阻塞式HTTP请求库，当我们发出一个请求后，程序会一直等待服务器响应，直到得到响应后才会进行下一步处理。这个过程很耗时间。如果程序可以在这个等待过程中做一些其他事情，则会大大提高爬取效率。aiohttp就是这样提供异步web服务的库，从python3.5开始加入了async/await关键字，使得回调的写法更加直观与人性化。aiohttp借助于async/await。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install aiohttp</span><br><span class="line"></span><br><span class="line">pip install cchardet aiodns</span><br></pre></td></tr></table></figure>

<h5 id="lxml的安装"><a href="#lxml的安装" class="headerlink" title="lxml的安装"></a>lxml的安装</h5><p>lxml是python的解析库，支持HTML和XML解析，支持XPath解析方式。</p>
<p>如果没有任何报错，则证明安装成功。如果出现报锚，比如提示缺少libxml2库等信息，可以采用wheel方式安装。推荐直接到这里（链接为：<a href="http://www.lfd.uci.edu/-goblke/pythonlibs/#lxml）下载对应的wheel文件，找到本地安装Python版本和系统对应的lxml版本，例如Windows64位、Python3.6，就选作lxml-3" target="_blank" rel="noopener">http://www.lfd.uci.edu/-goblke/pythonlibs/#lxml）下载对应的wheel文件，找到本地安装Python版本和系统对应的lxml版本，例如Windows64位、Python3.6，就选作lxml-3</a> .8.0-cp36-cp36m-win _ amd64. whl，将其下载到本地。然后pip。</p>
<h5 id="Beauitful-Soup安装"><a href="#Beauitful-Soup安装" class="headerlink" title="Beauitful Soup安装"></a>Beauitful Soup安装</h5><p>Beauitful Soup是python的一个HTML或XML解析库，我们可以用它方便地从网页中提取数据，它拥有强大的API与多样的解析方式。</p>
<p><strong>版本管理真是个奇妙的事情</strong>，好好用conda（为啥镜像源还会报错） ，以及pip与pip3，pycharm里安装了bs4，cmd中安装了beautifulsoup4，但是import的时候还是报错，就很难过。看了挺多中文办法，不得行。还是stack overflow上讲的明白：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ou have the module installed for Python 2.7, however you&apos;re using and trying to import it with Python 3.6.</span><br><span class="line"></span><br><span class="line">You have to use pip3 like you use python3.</span><br></pre></td></tr></table></figure>

<p>注意这里我们虽然安装的是beautifulsoup4这个包，但是在引入的时候却是bs4，因为这个包源代码本身的库文件夹的名称就是bs4.所以安装完成之后，这个库文件夹就被移入到本机python3的lib库里，所以识别到的库文件名就是bs4.</p>
<h5 id="pyquery的安装"><a href="#pyquery的安装" class="headerlink" title="pyquery的安装"></a>pyquery的安装</h5><p>强大的网页解析工具，提供了和jQuery类似的语法来解析HTML文档，支持CSS选择器。</p>
<h5 id="tesserocr安装"><a href="#tesserocr安装" class="headerlink" title="tesserocr安装"></a>tesserocr安装</h5><p>爬虫过程中难免会遇到各种各样验证码，并且还是图形验证码，此时可以用OCR来识别。</p>
<p>OCR，即Optical Character Recognition，光学字符识别，指通过扫描字符，然后通过其形状将其翻译成电子文本的过程。tesserocr是Python的一个OCR识别库，实际上是对tesseract做的一层python API封装，所以在安装前者前要安装后者。下载tesseract，记住勾选Additional language data来安装OCR识别支持的语言包。</p>
<p><strong>安装完后注意要配置环境变量，现在终于知道环境变量是用来干嘛的了，是为了在使用命令行的时候能够直接使用某种命令，如python，tesseract。</strong></p>
<p>在系统环境变量中，Path添加tesseract的安装目录。在系统环境变量中，添加变量“TESSDATA_PREFIX”，变量值为tessdata文件夹所在路径。<strong>注意系统要重启。</strong></p>
<p>命令：</p>
<p>tesseract [xxx.jpg/png/etc] [result.txt|stdout] [-l eng | chi_sim]</p>
<p>如果要输入文字到result.txt中，需要以管理员身份运行cmd。指定字库的时候，只需要字库的前缀。eng.traineddata，只输入并且只能输入eng。</p>
<p><strong>tesseract命令第一个参数为图片名称，第二个参数result为结果保存的目标文件名，-l指定使用的语言包，eng即英文。</strong></p>
<p>验证安装：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line">import pytesseract</span><br><span class="line"> </span><br><span class="line">text = pytesseract.image_to_string(Image.open(r&apos;D:\My Tools\image.png&apos;))</span><br><span class="line">print(text)</span><br><span class="line">//Image.open读取了图片文件，然后调用pytesseract的image_to_string方法。</span><br></pre></td></tr></table></figure>

<h4 id="数据库的安装："><a href="#数据库的安装：" class="headerlink" title="数据库的安装："></a>数据库的安装：</h4><p>作为数据存储的重要部分，数据库必不可少，可以分为关系型数据库和非关系型数据库，前者数据库以表的形式存储，后哦这存储形式为键值对，更加灵活。MySQL是一个轻量级的关系数据库，MongoDB使用C++编写的非关系型数据库，是一个基于分布式文件存储的开源数据库系统（啥意思），其存储方式类似JSON对象，字段值可以包含其他文档，数组以及文档数组。</p>
<p>可视化工具：RoboMongo/Robo 3T，Studio 3T。</p>
<p>安装了Redis，Host没找对，直接输入local就行，结果搞了很久。看起来一直在努力找资料，实际上太懒了根本没动脑子。</p>
<h4 id="存储库的安装："><a href="#存储库的安装：" class="headerlink" title="存储库的安装："></a>存储库的安装：</h4><p>PyMySQL/PyMongo/redis-py（用于与redis交互）</p>
<p>RedisDump安装：他是一个用于Redis数据导入导出的工具，基于Ruby实现。</p>
<p>安装Ruby后就可执行gem命令，类似于pip。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem install redis-dump</span><br></pre></td></tr></table></figure>

<p>验证安装</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-dump</span><br><span class="line">redis-load</span><br></pre></td></tr></table></figure>

<h4 id="Web库的安装："><a href="#Web库的安装：" class="headerlink" title="Web库的安装："></a>Web库的安装：</h4><p>Flask，Django这样的一些web服务程序是基于python开发的，我们可以拿他来开发网站和接口。目前主要使用这些web服务程序来搭建一些API接口供爬虫使用。</p>
<p>API:Application Programming Interface，应用程序接口，是一些预先定义的函数，或者说软件系统不同组成部分衔接的约定。</p>
<p>目的是提供应用程序与开发人员基于某软件或硬件得以访问一组例程的能力，而又无需访问原码，或理解内部工作机制的细节。</p>
<h5 id="Flask安装"><a href="#Flask安装" class="headerlink" title="Flask安装"></a>Flask安装</h5><p>Flask是一个轻量级的web服务程序，此处主要用来做一些API服务。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install flask</span><br></pre></td></tr></table></figure>

<p>验证安装总没法成功，再找找原因。</p>
<p>验证的脚本出错了，问题在于最后一段。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python </span><br><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">#导入了Flask类</span><br><span class="line">from flask import Flask</span><br><span class="line">#创建一个该类的实例</span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line">#route装饰器告诉告诉Flask什么样的URL能够触发函数</span><br><span class="line">@app.route(&apos;/&apos;)</span><br><span class="line">#这个函数的名字也在生成 URL 时被特定的函数采用，这个函数返回我们想要显示在用户#浏览器中的信息。</span><br><span class="line">def hello_world():</span><br><span class="line">    return &apos;Hello World!&apos;</span><br><span class="line">#最后我们用 run() 函数来让应用运行在本地服务器上。 其中 if __name__ #==&apos;__main__&apos;: 确保服务器只会在该脚本被 Python 解释器直接执行的时候才会运行，而不是作为模块导入的时候。</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    app.run()</span><br></pre></td></tr></table></figure>

<p>后面将利用Flask+Redis维护动态代理池和Cookie池。</p>
<h5 id="Tornado安装"><a href="#Tornado安装" class="headerlink" title="Tornado安装"></a>Tornado安装</h5><p>Tornado是一个支持异步的Web框架，通过使用非阻塞I/O流，支持上千万的开放连接。</p>
<p>pip3安装，后面将利用Tornado+redis来搭建一个ADSL拨号代理池。</p>
<h4 id="APP爬取相关库的安装："><a href="#APP爬取相关库的安装：" class="headerlink" title="APP爬取相关库的安装："></a>APP爬取相关库的安装：</h4><p>除了Web网页，爬虫也可以抓取APP数据。<strong>APP中页面加载所需要的数据通过请求服务器的接口获取。</strong>由于APP没有浏览器这种直观看到后台请求的数据，所以<strong>主要使用一些抓包工具来抓取数据</strong>。一些<strong>简单的接口可以使用Charles或者mitmproxy分析</strong>，找出规律，然后直接利用程序模拟来抓取。<strong>更复杂的接口利用mitmdump</strong>，对抓取到的请求进行实时处理与保存。自动化APP工具：Appium，可以像selenium一样对App进行自动化控制，模拟点击等操作。</p>
<h5 id="Cherles的安装"><a href="#Cherles的安装" class="headerlink" title="Cherles的安装"></a>Cherles的安装</h5><p>Charles是一个网络抓包工具，这里主要选用为移动端抓包工具。</p>
<p>证书配置：现在很多页面都在向HTTPS发展，如果一个App通信应用了HTTPS协议，那么它的通信数据是会被加密的，常规的抓包方法无法识别请求的内部数据。如果要做HTTPS抓包的话，需要配置相关的SSL证书。Help&gt;SSL Proxying&gt;install Charles Root Certificate,将所有的证书放入下列存储，然后浏览选择受信任的根证书颁发机构。</p>
<p><strong>使用Charles代理手机请求：找WLAN的设定就找了很久，长按修改，进阶模式。但是设置好代理之后一直连接不上网络，监听不了，是啥原因？等到后面实战移动端的时候再肝一下。</strong></p>
<h5 id="mitmproxy的安装"><a href="#mitmproxy的安装" class="headerlink" title="mitmproxy的安装"></a>mitmproxy的安装</h5><p>暂时不用</p>
<h5 id="Appium的安装"><a href="#Appium的安装" class="headerlink" title="Appium的安装"></a>Appium的安装</h5><p>Appium负责驱动移动端来完成一系列操作，对于Android来说，它使用UIAutomator和Selendroid来实现驱动。Android开发环境配置，之后再看。Android SDK与Android Studio</p>
<h4 id="爬虫框架的安装："><a href="#爬虫框架的安装：" class="headerlink" title="爬虫框架的安装："></a>爬虫框架的安装：</h4><p><strong>我们直接用requests,Selenium等库写爬虫，如果爬取量不是太大，速度要求不高，完全可以满足需求。但是写多了就会发现其内部许多代码与组件是完全可以复用的。把这些组件抽离出来，将各个功能模块化，就会形成爬虫框架。</strong></p>
<h5 id="pyspider的安装"><a href="#pyspider的安装" class="headerlink" title="pyspider的安装"></a>pyspider的安装</h5><p>安装完报错，讲到时再试。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;C:\Users\Lenovo\AppData\Local\Programs\Python\Python37\Scripts\pyspider-script.py&quot;, line 11, in &lt;module&gt;</span><br><span class="line">    load_entry_point(&apos;pyspider==0.3.10&apos;, &apos;console_scripts&apos;, &apos;pyspider&apos;)()</span><br><span class="line">  File &quot;c:\users\lenovo\appdata\local\programs\python\python37\lib\site-packages\pkg_resources\__init__.py&quot;, line 489, in load_entry_point</span><br><span class="line">    return get_distribution(dist).load_entry_point(group, name)</span><br><span class="line">  File &quot;c:\users\lenovo\appdata\local\programs\python\python37\lib\site-packages\pkg_resources\__init__.py&quot;, line 2793, in load_entry_point</span><br><span class="line">    return ep.load()</span><br><span class="line">  File &quot;c:\users\lenovo\appdata\local\programs\python\python37\lib\site-packages\pkg_resources\__init__.py&quot;, line 2411, in load</span><br><span class="line">    return self.resolve()</span><br><span class="line">  File &quot;c:\users\lenovo\appdata\local\programs\python\python37\lib\site-packages\pkg_resources\__init__.py&quot;, line 2417, in resolve</span><br><span class="line">    module = __import__(self.module_name, fromlist=[&apos;__name__&apos;], level=0)</span><br><span class="line">  File &quot;c:\users\lenovo\appdata\local\programs\python\python37\lib\site-packages\pyspider\run.py&quot;, line 231</span><br><span class="line">    async=True, get_object=False, no_input=False):</span><br></pre></td></tr></table></figure>

<h5 id="Scrapy的安装"><a href="#Scrapy的安装" class="headerlink" title="Scrapy的安装"></a>Scrapy的安装</h5><p>连上V2ray和不连v2ray，在用镜像源安装的时候差别居然这么大。注意安装好各种前置的库。</p>
<h5 id="Scrapy-Splash的安装"><a href="#Scrapy-Splash的安装" class="headerlink" title="Scrapy-Splash的安装"></a>Scrapy-Splash的安装</h5><p>需要Docker</p>
<h5 id="Scrapy-Redis的安装"><a href="#Scrapy-Redis的安装" class="headerlink" title="Scrapy-Redis的安装"></a>Scrapy-Redis的安装</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install scrapy-redis</span><br></pre></td></tr></table></figure>

<h4 id="部署相关库的安装："><a href="#部署相关库的安装：" class="headerlink" title="部署相关库的安装："></a>部署相关库的安装：</h4><p>如果想要大规模抓取数据，那么一定会用到分布式爬虫。对于分布式爬虫，需要多台主机，每台主机上有多个爬虫任务，但只有一份源代码。此时需要做的就是将一份代码同时部署到多台主机上来运行。</p>
<p>对于Scrapy，名为Scrapyd的扩展组件能够帮助我们远程管理Scrapy任务，包括部署源码，启动任务，监听任务等等。Scrapy-Client和Scrapyd API非常实用。</p>
<p>或者利用Docker集群部署，只需要将爬虫只作为Docker镜像。只要主机中安装了Docker，就能够直接运行爬虫，无需担心环境与版本问题。</p>
<h5 id="Docker的安装"><a href="#Docker的安装" class="headerlink" title="Docker的安装"></a>Docker的安装</h5><p>hyper-v，谜之报错，安装完发现不需要，不需要也就算了还不共存，不共存也就算了还不能删。</p>
<p>可能是要安装docker for Windows？可不是说只支持专业版，这样一说要修改注册表？</p>
<p>修改了注册表，但是依旧报错。</p>
<p>老子不装了，等到后面学分布式爬虫再说。注意不能学啥都学的太浅薄，不然根本没有用。</p>
<h5 id="Scrapyd的安装"><a href="#Scrapyd的安装" class="headerlink" title="Scrapyd的安装"></a>Scrapyd的安装</h5><p>需要linux环境，后面有需要再看。</p>
<h5 id="Scrapyd-Client的安装"><a href="#Scrapyd-Client的安装" class="headerlink" title="Scrapyd-Client的安装"></a>Scrapyd-Client的安装</h5><p>基于Scrapyd</p>
<h5 id="Scrapyd-API安装"><a href="#Scrapyd-API安装" class="headerlink" title="Scrapyd API安装"></a>Scrapyd API安装</h5><p>基于Scrapyd</p>
<h5 id="Scrapyrt的安装"><a href="#Scrapyrt的安装" class="headerlink" title="Scrapyrt的安装"></a>Scrapyrt的安装</h5><p>Scrapyrt为Scrapy提供了一个调度的HTTP接口，有了它我们可以通过请求一个HTTP接口来调度Scrapy任务。Scarpyrt比Scrapyd更轻量，如果不需要分布式多任务，可简单实用Scarpyrt实现远程Scrapy任务调度。</p>
<h5 id="Gerapy的安装"><a href="#Gerapy的安装" class="headerlink" title="Gerapy的安装"></a>Gerapy的安装</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install gerapy</span><br></pre></td></tr></table></figure>

<h3 id="第二章：爬虫基础"><a href="#第二章：爬虫基础" class="headerlink" title="第二章：爬虫基础"></a>第二章：爬虫基础</h3><h4 id="HTTP基本原理"><a href="#HTTP基本原理" class="headerlink" title="HTTP基本原理"></a>HTTP基本原理</h4><h5 id="URI与URL"><a href="#URI与URL" class="headerlink" title="URI与URL"></a>URI与URL</h5><p>URI：Uniform Resource Identifier，统一资源标识符。URL：Universal Resource Locator，统一资源定位符。URL是URI的真子集，URI还包括一个子集叫做URN：Universal Resource Name，统一资源名称。URN只命名资源而不定位资源。如URN:isbn：xxxx指定了一本书的ISBN，能够唯一标识这本书，但是没有定位。</p>
<p>URL一定能够定位但可能没有名称，URN一定有名称但可能不能定位。</p>
<h5 id="超文本hypertext"><a href="#超文本hypertext" class="headerlink" title="超文本hypertext"></a>超文本hypertext</h5><p>浏览器中看到的网页就是一系列HTML代码（超文本）解析而成，最后呈现出来并不以代码本身，而是标识出的别的形式。</p>
<h5 id="HTTP与HTTPS"><a href="#HTTP与HTTPS" class="headerlink" title="HTTP与HTTPS"></a>HTTP与HTTPS</h5><p>两者都是访问资源需要的协议类型，有时还会看到ftp，sftp，smb开头的URL，它们都是协议类型。在爬虫中一般抓取的是HTTP与HTTPS协议的。</p>
<p>HTTP：Hyper Text Transfer Protocol，超文本传输协议。<strong>HTTP协议用于从网络传输超文本数据到本地浏览器的传输协议。</strong>目前广泛使用的是HTTP1.1版本。</p>
<p>HTTPS的全称是Hyper Text Transfer Protocol over Secure Socket Layer，是在HTTP下加入SSL层，HTTP的安全版。</p>
<p>HTPPS的安全基础是SSL，因此通过它传输的内容都是经过SSL加密的，主要有两种作用：</p>
<ol>
<li>建立一个信息安全通道来保证数据的安全。</li>
<li>确认网站的真实性：凡是使用了HTTPS的网站，都可以通过点击浏览器的锁头标志来查看网站认证之后的真实信息。也可以通过CA机构颁发的安全签章来查询。</li>
</ol>
<p>某些网站虽然使用了HTTPS协议，但是还是被浏览器提示不安全，这是因为其CA证书是自行签发而不被CA机构所信任，但实际上仍然是经过SSL加密的。<strong>如果要爬取这样的站点，就要忽略证书的选项，否则会提示SSL链接错误。</strong></p>
<h5 id="HTTP请求过程"><a href="#HTTP请求过程" class="headerlink" title="HTTP请求过程"></a>HTTP请求过程</h5><p>访问网站的过程实际上是在浏览器中输入一个URL后，浏览器向网站所在的服务器发送一个请求，网站服务器接收到这个请求后进行处理与解析，然后返回对应的响应，接着传回给浏览器。<strong>这个”响应”里包含了页面的源代码等内容</strong>，浏览器对其进行解析后便呈现了出来。</p>
<p>打开Chrome浏览器，右键选择“检查”，Network监听组件能够直观地现实访问当前请求网页时所发生的所有网络请求和响应。其中各列表示的意思如下：</p>
<p>Name：请求的名称，一般会将URL的最后一部分内容当作名称。</p>
<p>Status：响应的状态码，通过状态码我们可以判断发送了请求之后是否得到了正常的响应。</p>
<p>Type：请求的文档类型，有jpeg，png，stylesheet，document等。</p>
<p>Initiator：请求源，用于标记请求是由哪个对象或者进程发起的。</p>
<p>Size：从服务器下载的文件和请求资源的大小。如果是从缓存中取得的资源，则该列会显示from cache。</p>
<p>Time：发起请求到获取响应所用的总时间。</p>
<p>Waterfall：网络请求的可视化瀑布流。</p>
<h5 id="请求"><a href="#请求" class="headerlink" title="请求"></a>请求</h5><p>由客户端向服务端发出，分为请求方法，请求网址，请求头与请求体。</p>
<p><strong>请求方法</strong>：常见的请求方法有GET与POST。<strong>GET：</strong>在浏览器中输入URL并回车，便发起了一个URL请求，请求的参数会直接包含到URL中，比如<a href="https://www.baidu.com/s?wd=python,参数wd就表示要搜索的关键字。POST请求大多在表单提交时发起，用于提交数据等，其数据以表单的形式传输，而不会体现在URL中。" target="_blank" rel="noopener">https://www.baidu.com/s?wd=python,参数wd就表示要搜索的关键字。POST请求大多在表单提交时发起，用于提交数据等，其数据以表单的形式传输，而不会体现在URL中。</a></p>
<p>二者区别：GET请求的参数包含在URL中，数据能够直接看到。而POST的数据会包含在请求体中，URL中看不到。<strong>GET请求提交的数据最多只有1024字节，而POST无限制。</strong>一般来说传递敏感信息与发送较大文件，都用POST请求。</p>
<table>
<thead>
<tr>
<th>1</th>
<th>GET</th>
<th>请求指定的页面信息，并返回实体主体。</th>
</tr>
</thead>
<tbody><tr>
<td>2</td>
<td>HEAD</td>
<td>类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头</td>
</tr>
<tr>
<td>3</td>
<td>POST</td>
<td>向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。</td>
</tr>
<tr>
<td>4</td>
<td>PUT</td>
<td>从客户端向服务器传送的数据取代指定的文档的内容。</td>
</tr>
<tr>
<td>5</td>
<td>DELETE</td>
<td>请求服务器删除指定的页面。</td>
</tr>
<tr>
<td>6</td>
<td>CONNECT</td>
<td>HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。</td>
</tr>
<tr>
<td>7</td>
<td>OPTIONS</td>
<td>允许客户端查看服务器的性能。</td>
</tr>
<tr>
<td>8</td>
<td>TRACE</td>
<td>回显服务器收到的请求，主要用于测试或诊断。</td>
</tr>
<tr>
<td>9</td>
<td>PATCH</td>
<td>是对 PUT 方法的补充，用来对已知资源进行局部更新 。</td>
</tr>
</tbody></table>
<p><strong>请求网址</strong>：URL，能够确定请求的资源。</p>
<p><strong>请求头</strong>：用于说明服务器要使用的附加信息，如Cookie，Referer，User-Agent</p>
<p>常用的头信息：</p>
<p>Accept：请求报头域，用于指定客户端可以接受哪些类型的信息。</p>
<p>Host：用于指定请求资源的主机IP和端口号，其内容为URL的原始服务器/网关的位置。从HTTP1.1开始，请求必须包含此内容。</p>
<p>Cookie：网站为了辨别用户进行会话跟踪而存储在用户本地的数据。主要功能是维持当前会话，即使再次刷新也能够无需再次输入信息。Cookies里有信息标识了对应服务器的会话，每次浏览器在请求该站点页面时，都会在请求头中加入Cookies并将其发送给服务器。服务器通过Cookies识别出身份，直接返回登陆后的页面。</p>
<p>Referer：用于标识这个请求的来源，服务器可以拿到此信息做相应处理。</p>
<p>User-Agent：UA，特殊的字符串头，可以使服务器识别客户使用的操作系统（版本）/浏览器(版本)。<strong>在做爬虫时加上此信息，可以伪装成浏览器，否则很可能被识别为爬虫。</strong></p>
<p>Content-Type：互联网媒体类型，MIME类型。它用于表示具体请求中的媒体类型信息：</p>
<blockquote>
<p>text/html代表HTML格式(XML数据)。image/gif代表GIF图片。application/json代表JSON类型。只有设置Content-Type为application/x-www-form-urlencoded，才会以表单数据形式提交。appilcation/json来提交(序列化)JSON数据。multipart/form-data来上传(表单)文件。blabla。</p>
</blockquote>
<p>在爬虫中，如果要构造POST请求，需要使用正确的Content-Type，并了解各种请求库的各个参数设置时使用的是哪种Type，不然会导致POST提交后无法正常响应。</p>
<h5 id="请求体："><a href="#请求体：" class="headerlink" title="请求体："></a>请求体：</h5><p>请求体一般承载的内容是POST请求中的表单数据，相对于GET请求，请求体为空。</p>
<h5 id="响应："><a href="#响应：" class="headerlink" title="响应："></a>响应：</h5><p>由服务端返回给客户端，可以分成响应状态码Request Status Code，响应头Response Headers和响应体Response Body。</p>
<p>响应状态码：表示服务器的响应状态，在爬虫中我们根据状态码来判断响应状态。</p>
<table>
<thead>
<tr>
<th>1**</th>
<th>信息，服务器收到请求，需要请求者继续执行操作</th>
</tr>
</thead>
<tbody><tr>
<td>2**</td>
<td>成功，操作被成功接收并处理</td>
</tr>
<tr>
<td>3**</td>
<td>重定向，需要进一步的操作以完成请求</td>
</tr>
<tr>
<td>4**</td>
<td>客户端错误，请求包含语法错误或无法完成请求</td>
</tr>
<tr>
<td>5**</td>
<td>服务器错误，服务器在处理请求的过程中发生了错误</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>100</th>
<th>Continue</th>
<th>继续。客户端应继续其请求</th>
</tr>
</thead>
<tbody><tr>
<td>101</td>
<td>Switching Protocols</td>
<td>切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>200</td>
<td>OK</td>
<td>请求成功。一般用于GET与POST请求</td>
</tr>
<tr>
<td>201</td>
<td>Created</td>
<td>已创建。成功请求并创建了新的资源</td>
</tr>
<tr>
<td>202</td>
<td>Accepted</td>
<td>已接受。已经接受请求，但未处理完成</td>
</tr>
<tr>
<td>203</td>
<td>Non-Authoritative Information</td>
<td>非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本</td>
</tr>
<tr>
<td>204</td>
<td>No Content</td>
<td>无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档</td>
</tr>
<tr>
<td>205</td>
<td>Reset Content</td>
<td>重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域</td>
</tr>
<tr>
<td>206</td>
<td>Partial Content</td>
<td>部分内容。服务器成功处理了部分GET请求</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>300</td>
<td>Multiple Choices</td>
<td>多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择</td>
</tr>
<tr>
<td>301</td>
<td>Moved Permanently</td>
<td>永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替</td>
</tr>
<tr>
<td>302</td>
<td>Found</td>
<td>临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI</td>
</tr>
<tr>
<td>303</td>
<td>See Other</td>
<td>查看其它地址。与301类似。使用GET和POST请求查看</td>
</tr>
<tr>
<td>304</td>
<td>Not Modified</td>
<td>未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源</td>
</tr>
<tr>
<td>305</td>
<td>Use Proxy</td>
<td>使用代理。所请求的资源必须通过代理访问</td>
</tr>
<tr>
<td>306</td>
<td>Unused</td>
<td>已经被废弃的HTTP状态码</td>
</tr>
<tr>
<td>307</td>
<td>Temporary Redirect</td>
<td>临时重定向。与302类似。使用GET请求重定向</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>400</td>
<td>Bad Request</td>
<td>客户端请求的语法错误，服务器无法理解</td>
</tr>
<tr>
<td>401</td>
<td>Unauthorized</td>
<td>请求要求用户的身份认证</td>
</tr>
<tr>
<td>402</td>
<td>Payment Required</td>
<td>保留，将来使用</td>
</tr>
<tr>
<td>403</td>
<td>Forbidden</td>
<td>服务器理解请求客户端的请求，但是拒绝执行此请求</td>
</tr>
<tr>
<td>404</td>
<td>Not Found</td>
<td>服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置”您所请求的资源无法找到”的个性页面</td>
</tr>
<tr>
<td>405</td>
<td>Method Not Allowed</td>
<td>客户端请求中的方法被禁止</td>
</tr>
<tr>
<td>406</td>
<td>Not Acceptable</td>
<td>服务器无法根据客户端请求的内容特性完成请求</td>
</tr>
<tr>
<td>407</td>
<td>Proxy Authentication Required</td>
<td>请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权</td>
</tr>
<tr>
<td>408</td>
<td>Request Time-out</td>
<td>服务器等待客户端发送的请求时间过长，超时</td>
</tr>
<tr>
<td>409</td>
<td>Conflict</td>
<td>服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突</td>
</tr>
<tr>
<td>410</td>
<td>Gone</td>
<td>客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置</td>
</tr>
<tr>
<td>411</td>
<td>Length Required</td>
<td>服务器无法处理客户端发送的不带Content-Length的请求信息</td>
</tr>
<tr>
<td>412</td>
<td>Precondition Failed</td>
<td>客户端请求信息的先决条件错误</td>
</tr>
<tr>
<td>413</td>
<td>Request Entity Too Large</td>
<td>由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息</td>
</tr>
<tr>
<td>414</td>
<td>Request-URI Too Large</td>
<td>请求的URI过长（URI通常为网址），服务器无法处理</td>
</tr>
<tr>
<td>415</td>
<td>Unsupported Media Type</td>
<td>服务器无法处理请求附带的媒体格式</td>
</tr>
<tr>
<td>416</td>
<td>Requested range not satisfiable</td>
<td>客户端请求的范围无效</td>
</tr>
<tr>
<td>417</td>
<td>Expectation Failed</td>
<td>服务器无法满足Expect的请求头信息</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>500</td>
<td>Internal Server Error</td>
<td>服务器内部错误，无法完成请求</td>
</tr>
<tr>
<td>501</td>
<td>Not Implemented</td>
<td>服务器不支持请求的功能，无法完成请求</td>
</tr>
<tr>
<td>502</td>
<td>Bad Gateway</td>
<td>作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应</td>
</tr>
<tr>
<td>503</td>
<td>Service Unavailable</td>
<td>由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中</td>
</tr>
<tr>
<td>504</td>
<td>Gateway Time-out</td>
<td>充当网关或代理的服务器，未及时从远端服务器获取请求</td>
</tr>
<tr>
<td>505</td>
<td>HTTP Version not supported</td>
<td>服务器不支持请求的HTTP协议的版本，无法完成处理</td>
</tr>
</tbody></table>
<h5 id="响应头："><a href="#响应头：" class="headerlink" title="响应头："></a>响应头：</h5><p>包含服务器对请求的应答信息：</p>
<p>Date:响应标识产生的时间</p>
<p>Last-Modified：指定资源的最后修改时间。</p>
<p>Content-Encoding：指定响应内容的编码。</p>
<p>Server：包含服务器的信息，名称，版本号等。</p>
<p>Content-Type:返回的文档类型。</p>
<p>Set-Cookie：设置Cookies。响应头中的Set-Cookie告诉浏览器需要将此内容放在Cookies中，下次请求携带Cookies请求。</p>
<p>Expires:指定响应的过期时间，可以使代理服务器或浏览器将加载的内容更新到缓存中。如果再次访问，就可以直接从缓存中加载，以降低服务器负载，缩短加载时间。</p>
<h5 id="响应体："><a href="#响应体：" class="headerlink" title="响应体："></a>响应体：</h5><p>响应的正文数据都在响应体中，例如请求网页时，其响应体就是王爷的HTML代码。请求图片时便是图片的二进制数据。<strong>做爬虫请求网页后要解析的内容就是响应体。</strong></p>
<h4 id="网页基础"><a href="#网页基础" class="headerlink" title="网页基础"></a>网页基础</h4><p>基本组成，结构和节点等内容。</p>
<h5 id="网页的组成："><a href="#网页的组成：" class="headerlink" title="网页的组成："></a>网页的组成：</h5><p>HTML.CSS.JavaScript，HTML相当于骨架，CSS相当于皮肤，JavaScript相当于肌肉。</p>
<p>HTML：由于学校课程学过比较熟悉，它是用来描述网页的一种超文本标记语言。不同类型的文字通过不同类型的标签来表示，如img，p等标签。<strong>他们之间的布局又常通过布局标签div嵌套组合而成</strong>，各种标签通过不同的排列和嵌套形成网页的框架。</p>
<p>CSS：只有HTML的页面布局并不美观，CSS全称Cascading Style Sheets,即层叠样式表。层叠是指当在HTML中引用了数个样式文件，并且<strong>样式发生冲突时，浏览器能够依据层叠顺序处理</strong>。样式指网页中文字大小，颜色，元素间距排列等格式。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//大括号前是一个CSS选择器，意思是选择id为head_wrpper且class为s-ps-lite的节点，然后再选中其内部的class为s-p-top的节点。大括号内部写的是样式规则。</span><br><span class="line">#head_wrapper.s-ps-islite,s-p-top&#123;</span><br><span class="line">//position指定了这个元素的布局方式为绝对布局</span><br><span class="line">	position:absolute;</span><br><span class="line">//bottom指定元素的下边距为40px</span><br><span class="line">	bottom:40px;</span><br><span class="line">//width指定了宽度为100%占满父元素</span><br><span class="line">	width:100%;</span><br><span class="line">//height指定元素的高度</span><br><span class="line">	height:181px;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在网页中，一般会统一定义整个网页的CSS样式规则，并写入CSS文件中（后缀为css）。在HTML中只要用link标签就能够引入写好的css文件。</p>
<h5 id="JavaScript"><a href="#JavaScript" class="headerlink" title="JavaScript:"></a>JavaScript:</h5><p>是一种脚本语言，HTML与CSS配合使用，提供给用户的只是一种静态的信息缺乏交互，这要靠JS实现。JS通常也是以单独的文件加载的，后缀为js，通过在HTML<script>标签引用。</p>
<h5 id="网页的结构："><a href="#网页的结构：" class="headerlink" title="网页的结构："></a>网页的结构：</h5><p>title标签定义标题，会显示在网页的选项卡中，而不会显示在正文。body标签是网页正文中显示的内容，div标签定义了网页中的区块，它的id是container，属于非常常用属性，并且id的内容在网页中是唯一的，便于定位。class=wrapper的div标签，经常与CSS配合使用来设定样式。每个标签元素都有自己的class属性。</p>
<h5 id="节点树以及节点之间的关系："><a href="#节点树以及节点之间的关系：" class="headerlink" title="节点树以及节点之间的关系："></a>节点树以及节点之间的关系：</h5><p>在THML中，所有标签的定义都是节点，它们构成了一个HTML DOM树。DOM全称Document Object Model，文档对象模型。定义了访问HTML与XML的文档标准。W3C文档对象模型DOM是中立于平台和语言的接口，它允许程序和脚本动态地访问和更新文档的内容，结构与样式。</p>
<p>W3C标准被分为3个不同的部分：</p>
<p><strong>核心DOM：</strong>针对任何结构化文档的标准模型</p>
<p><strong>XML DOM：</strong>针对XML文档的标准模型</p>
<p><strong>HTML DOM：</strong>针对HTML文档的标准模型</p>
<p>根据W3C的HTML DOM标准，HTML文档中的所有内容都是节点。</p>
<ol>
<li>整个文档是一个文档节点。</li>
<li>每个HTML元素是一个元素节点</li>
<li>HTML元素内的文本是文本节点。</li>
<li>每个HTML属性是属性节点。</li>
<li>注释是注释节点。</li>
</ol>
<p>通过HTML DOM，树中的所有节点均可通过JavaScript访问，所有HTML节点元素均可被修改,也可以被创立和删除。节点树中的节点彼此拥有层级关系，通常通过父，子，兄弟来描述这些关系。在节点树中，<strong>顶端节点通常称为根</strong></p>
<p><strong>选择器：</strong></p>
<p>分为派生选择器，通过依据元素在其位置的上下文关系来定义样式，派生选择器允许你根据文档的上下文关系来确定某个标签的样式。通过合理地使用派生选择器，我们可以使 HTML 代码变得更加整洁。id选择器，可以为标有特定id的HTML元素指定特定样式，以一个#号表示。类选择器，以一个点号表示。属性选择器，可以为拥有指定属性的 HTML 元素设置样式，而不仅限于 class 和 id 属性。</p>
<h4 id="爬虫的基本原理："><a href="#爬虫的基本原理：" class="headerlink" title="爬虫的基本原理："></a>爬虫的基本原理：</h4><p>简单来说，爬虫就是获取网页并提取和保存信息的自动化程序。</p>
<h5 id="获取网页："><a href="#获取网页：" class="headerlink" title="获取网页："></a>获取网页：</h5><p>首要工作便是获取网页的源代码，因为源代码包含网页的所有信息。向网站发送一个请求，返回的响应体便是网页源代码，所以最关键的便是构造请求，然后接收到响应并将其解析出来。python提供了许多库来实现这个操作，请求和响应都可以用类库提供的数据结构表示。得到响应之后我们只需要解析数据结构中的Body部分即可。</p>
<h5 id="提取信息："><a href="#提取信息：" class="headerlink" title="提取信息："></a>提取信息：</h5><p>分析网页源代码最通用的方式是正则表达式。还有一些根据网页节点属性，CSS选择器或者Xpath提取网页信息的库。</p>
<h5 id="保存数据："><a href="#保存数据：" class="headerlink" title="保存数据："></a>保存数据：</h5><p>可以简单保存为txt/json，或者保存到数据库，或者远程服务器。</p>
<h5 id="自动化程序："><a href="#自动化程序：" class="headerlink" title="自动化程序："></a>自动化程序：</h5><p>在抓取过程中进行各种异常处理，错误重试等操作。</p>
<p>除了网页源代码之外，还有些网页返回的不是HTML代码，而是JSON字符串（API接口大多如此），这样的数据方便传输与解析。还有各种二进制数据，如图片音频。以及各种扩展名的文件，只要能在浏览器访问到都可以抓取。</p>
<h5 id="JS渲染页面："><a href="#JS渲染页面：" class="headerlink" title="JS渲染页面："></a>JS渲染页面：</h5><p>有时候在urllib或者requests抓取页面时，得到的源代码与实际看到的不一样，这是因为现在网页越来越多地采用Ajax，前端模块化工具构建，如果整个页面都是JS渲染出来的（只要在最后加上<script src="xxx.js">即可完成页面渲染(渲染：构建渲染树，对各个元素进行位置计算、样式计算等等，然后根据渲染树对页面进行渲染（可以理解为“画”元素）)，就会得到一个HTML骨架。</p>
<p>在浏览器里打开这个页面时，首先加载这个HTML内容，然后浏览器会发现其中引入了一个app.js文件，接着请求这个文件，获得该文件后执行其中的JS代码改变HTML节点进行渲染。但是在用urllib/requests时不会帮我们继续加载这个JS文件。</p>
<p>对于这种情况，可以分析其后台Ajax接口，也可使用Selenium/Splash实现模拟JS渲染。</p>
<h4 id="会话和Cookies"><a href="#会话和Cookies" class="headerlink" title="会话和Cookies"></a>会话和Cookies</h4><p>最基本的HTML代码，将他放在某台具有固定公网IP的主机上，主机上装上Apache/Nginx服务器，这样这台主机就可以作为服务器，建立一个站点。这只是简单的静态网页无法实现交互。</p>
<h5 id="无状态HTTP："><a href="#无状态HTTP：" class="headerlink" title="无状态HTTP："></a>无状态HTTP：</h5><p>HTTP的无状态指HTTP协议对事物处理无记忆能力。单纯的一次HTTP请求完成过后，服务器不会记录前后状态的变化，不知道客户端的状态。这意味着如果后续需要处理前面的信息，则必须重传。<strong>保持前后状态一致的技术就是会话和Cookies。会话位于服务端，即网站服务器，用来保存用户的会话信息。Cookies位于客户端(浏览器端)，有了Cookies服务器在下次访问网页时会自动将其附加发送给服务器。</strong>鉴定出是哪个用户，是否为登录状态，返回对应的页面。</p>
<p>因此在爬虫中，处理需要登录才能访问的页面时，一般将登录成功后获取的Cookies放在请求头里直接请求。</p>
<p>会话：<strong>会话对象用来存储特定用户绘画所需的属性以及配置信息。</strong>这样当用户在应用程序的web页面之间跳转的时候，存储在会话之间的变量不会消失，会在整个用户会话中一致存在下去。</p>
<p>Cookies：网站为了辨识用户身份，进行会话跟踪而存储在本地终端上的数据。</p>
<p><strong>会话维持：</strong>当客户端第一次请求服务器时，服务器会返回一个请求头里带有Set-Cookie字段的响应给客户端，用于标识用户，客户端浏览器会把Cookies保存起来。下一次一起提交。</p>
<p><strong>属性结构：</strong>Cookies详解</p>
<p>开发者工具>Application>Storage>Cookies</p>
<p>Name：该Cookies的名称，一旦创建不可更改。</p>
<p>Value：该Cookies的值，如果为Unicode则为字符编码。如果为二进制数据BASE64编码。</p>
<p>Domain：可以访问该Cookies的域名，如果设置为.zhihu.com结尾的域名都可以访问该Cookie。</p>
<p>Max Age：该Cookie失效的时间，单位为s，与Expires一起使用。为正数在Max Age秒后失效，为负数关闭浏览器即失效。</p>
<p>Path：该Cookie的使用路径，设置为/则该域名下所有页面都可以访问该Cookie。</p>
<p>Size：Cookie大小。</p>
<p>HTTP字段：Cookie的httponly属性，如果为true则只有在HTTP头中会带有此Cookie信息，而不能通过document.cookie来访问此Cookie。</p>
<p>Secure：该Cookie是否仅被使用安全协议传输。安全协议：SSL，HTTPS。</p>
<p><img src="C:%5CUsers%5CLenovo%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200401212226395.png" alt="image-20200401212226395"></p>
<p>会话Cookie与持久Cookie，前者把Cookie放在浏览器内存里，后者把Cookie存放到客户端硬盘中。(严格意义来说只是Max Age的大小问题。)除非程序通知服务器删除一个会话，否则服务器会一直保留。这就需要服务器为会话设置一个失效时间。</p>
<h4 id="代理的基本原理："><a href="#代理的基本原理：" class="headerlink" title="代理的基本原理："></a>代理的基本原理：</h4><p>403 Forbidden>IP 访问频率太高>反爬虫措施>使用代理</p>
<h5 id="基本原理："><a href="#基本原理：" class="headerlink" title="基本原理："></a>基本原理：</h5><p>proxy server，代理网络用户去取得网络信息，通过中转站传递向服务器的请求与响应，这样服务器识别出的IP就不再是本机IP。</p>
<h5 id="代理作用"><a href="#代理作用" class="headerlink" title="代理作用:"></a>代理作用:</h5><ol>
<li>突破自身IP访问限制，访问不能访问的站点。</li>
<li>访问内网中的资源。</li>
<li>提高访问速度：通常代理服务器都设置一个较大的硬盘缓冲区，外界信息通过时会被保留在缓冲区，别的用户访问相同信息则直接从缓冲区取，提高访问速度。</li>
<li>隐藏真实IP，免受攻击。</li>
</ol>
<h5 id="代理分类："><a href="#代理分类：" class="headerlink" title="代理分类："></a>代理分类：</h5><p>根据协议区分/根据匿名程度区分：</p>
<ol>
<li><p>FTP代理服务器：用于访问FTP服务器，一般有上传，下载，缓存功能，port：21，2121。</p>
</li>
<li><p>HTTP代理服务器：主要用于访问网页，一般有内容过滤与缓存功能，port：80，8080，3128。</p>
</li>
<li><p>SSL/TLS代理：访问加密网站，一般有SSL/TLS加密功能，port：443。</p>
</li>
<li><p>RTSP代理：访问Real流媒体服务器，缓存功能，port：554.</p>
</li>
<li><p>Telnet代理：telnet远程控制（黑客入侵计算机时常用于隐藏身份？），port：23。</p>
</li>
<li><p>POP3/SMTP代理：主要用于POP3/SMTP方式收发邮件，缓存，port：110，25.</p>
</li>
<li><p>SOCKS代理：单纯传递数据包，不关系具体协议与用法，速度快很多，缓存，port：1080.分为SOCKS4和SOCKS5，前者支持TCP，后者支持TCP与UDP，还支持各种身份验证机制，服务器域名解析等，子集关系。</p>
</li>
<li><p>高度匿名代理：数据包原封不动转发，服务端看起来就是普通用户，IP为代理服务器IP。</p>
</li>
<li><p>普通匿名代理：会在数据包上做一些改动，服务端有可能察觉是代理服务器，可能追查到客户端IP。代理服务器通常加入的HTTP头又HTTP-VIA和HTTP-X-FORWARD-FOR。</p>
</li>
<li><p>透明代理：不但改动数据包，还告诉客户端真是IP。<strong>除了能用缓存技术提高浏览速度，能用内容过滤提高安全性，无其他 显著作用，如内网中的硬件防火墙。</strong></p>
</li>
</ol>
<h5 id="常见代理设置："><a href="#常见代理设置：" class="headerlink" title="常见代理设置："></a>常见代理设置：</h5><p>使用网上免费代理：最好使用高匿代理。</p>
<p>使用付费代理：网络上许多代理商。</p>
<p>ADSL拨号：拨一次号换一次IP，稳定性高。</p>
</script></p>
      
    </div>

        <div>
            
            <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">------This is my bottom line------</div>
    
</div>
            
        </div>
    
    
    
    


    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python3网络爬虫开发实战/" rel="tag"># python3网络爬虫开发实战</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/03/16/Anaconda教程/" rel="next" title="Anaconda教程">
                <i class="fa fa-chevron-left"></i> Anaconda教程
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/03/21/FTP配置/" rel="prev" title="FTP配置">
                FTP配置 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="Hy0uka">
            
              <p class="site-author-name" itemprop="name">Hy0uka</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archive">
              
                  <span class="site-state-item-count">54</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-globe"></i>
                友链
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://me.csdn.net/qq_39268483" title="playmake3r" target="_blank">playmake3r</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://me.csdn.net/qq_33356474" title="叮当猫" target="_blank">叮当猫</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://slipslopx.github.io/" title="SlioslopX" target="_blank">SlioslopX</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#第一章：环境配置"><span class="nav-number">1.</span> <span class="nav-text">第一章：环境配置</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Python3的安装"><span class="nav-number">1.0.1.</span> <span class="nav-text">Python3的安装</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#请求库的安装"><span class="nav-number">1.1.</span> <span class="nav-text">请求库的安装</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#ChromeDriver安装"><span class="nav-number">1.1.1.</span> <span class="nav-text">ChromeDriver安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#aiohttp的安装"><span class="nav-number">1.1.2.</span> <span class="nav-text">aiohttp的安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#lxml的安装"><span class="nav-number">1.1.3.</span> <span class="nav-text">lxml的安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Beauitful-Soup安装"><span class="nav-number">1.1.4.</span> <span class="nav-text">Beauitful Soup安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#pyquery的安装"><span class="nav-number">1.1.5.</span> <span class="nav-text">pyquery的安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#tesserocr安装"><span class="nav-number">1.1.6.</span> <span class="nav-text">tesserocr安装</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据库的安装："><span class="nav-number">1.2.</span> <span class="nav-text">数据库的安装：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#存储库的安装："><span class="nav-number">1.3.</span> <span class="nav-text">存储库的安装：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Web库的安装："><span class="nav-number">1.4.</span> <span class="nav-text">Web库的安装：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Flask安装"><span class="nav-number">1.4.1.</span> <span class="nav-text">Flask安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Tornado安装"><span class="nav-number">1.4.2.</span> <span class="nav-text">Tornado安装</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#APP爬取相关库的安装："><span class="nav-number">1.5.</span> <span class="nav-text">APP爬取相关库的安装：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Cherles的安装"><span class="nav-number">1.5.1.</span> <span class="nav-text">Cherles的安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#mitmproxy的安装"><span class="nav-number">1.5.2.</span> <span class="nav-text">mitmproxy的安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Appium的安装"><span class="nav-number">1.5.3.</span> <span class="nav-text">Appium的安装</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#爬虫框架的安装："><span class="nav-number">1.6.</span> <span class="nav-text">爬虫框架的安装：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#pyspider的安装"><span class="nav-number">1.6.1.</span> <span class="nav-text">pyspider的安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Scrapy的安装"><span class="nav-number">1.6.2.</span> <span class="nav-text">Scrapy的安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Scrapy-Splash的安装"><span class="nav-number">1.6.3.</span> <span class="nav-text">Scrapy-Splash的安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Scrapy-Redis的安装"><span class="nav-number">1.6.4.</span> <span class="nav-text">Scrapy-Redis的安装</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#部署相关库的安装："><span class="nav-number">1.7.</span> <span class="nav-text">部署相关库的安装：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Docker的安装"><span class="nav-number">1.7.1.</span> <span class="nav-text">Docker的安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Scrapyd的安装"><span class="nav-number">1.7.2.</span> <span class="nav-text">Scrapyd的安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Scrapyd-Client的安装"><span class="nav-number">1.7.3.</span> <span class="nav-text">Scrapyd-Client的安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Scrapyd-API安装"><span class="nav-number">1.7.4.</span> <span class="nav-text">Scrapyd API安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Scrapyrt的安装"><span class="nav-number">1.7.5.</span> <span class="nav-text">Scrapyrt的安装</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Gerapy的安装"><span class="nav-number">1.7.6.</span> <span class="nav-text">Gerapy的安装</span></a></li></ol></li></ol><li class="nav-item nav-level-3"><a class="nav-link" href="#第二章：爬虫基础"><span class="nav-number">2.</span> <span class="nav-text">第二章：爬虫基础</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#HTTP基本原理"><span class="nav-number">2.1.</span> <span class="nav-text">HTTP基本原理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#URI与URL"><span class="nav-number">2.1.1.</span> <span class="nav-text">URI与URL</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#超文本hypertext"><span class="nav-number">2.1.2.</span> <span class="nav-text">超文本hypertext</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HTTP与HTTPS"><span class="nav-number">2.1.3.</span> <span class="nav-text">HTTP与HTTPS</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#HTTP请求过程"><span class="nav-number">2.1.4.</span> <span class="nav-text">HTTP请求过程</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#请求"><span class="nav-number">2.1.5.</span> <span class="nav-text">请求</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#请求体："><span class="nav-number">2.1.6.</span> <span class="nav-text">请求体：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#响应："><span class="nav-number">2.1.7.</span> <span class="nav-text">响应：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#响应头："><span class="nav-number">2.1.8.</span> <span class="nav-text">响应头：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#响应体："><span class="nav-number">2.1.9.</span> <span class="nav-text">响应体：</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#网页基础"><span class="nav-number">2.2.</span> <span class="nav-text">网页基础</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#网页的组成："><span class="nav-number">2.2.1.</span> <span class="nav-text">网页的组成：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#JavaScript"><span class="nav-number">2.2.2.</span> <span class="nav-text">JavaScript:</span></a></li></ol></li></ol></li></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hy0uka</span>

  
</div>






  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>


<div>
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv" style="display:none">
    敝站总访问量 <span id="busuanzi_value_site_pv"></span> 次
    <span class="post-meta-divider">|</span>
</span>
<span id="busuanzi_container_site_uv" style="display:none">
    共计<span id="busuanzi_value_site_uv"></span>人次莅临寒舍
</span>
</div>



        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: true,
        appId: '0GX1G6E7gI1yVdjUJKYMnVXv-gzGzoHsz',
        appKey: 'BGdzmbmkaHb8MmitsLSmKyAg',
        placeholder: '风过留声，燕过留痕，君过留言！',
        avatar:'mm',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

  undefined
  <!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
 
 <canvas class="fireworks" style="position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;"></canvas>
 <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
 <script type="text/javascript" src="/js/fireworks.js"></script>
 
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginRootPath":"live2dw/"});</script></body>
</html>
